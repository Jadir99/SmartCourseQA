import os
import pickle
from flask import Flask, render_template, request, jsonify, session
from dotenv import load_dotenv
from PyPDF2 import PdfReader

from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.chat_models import ChatOpenAI
from langchain_classic.chains import RetrievalQA
from langchain_classic.retrievers import EnsembleRetriever
from langchain_community.retrievers import BM25Retriever

app = Flask(__name__)
app.secret_key = 'your-secret-key-change-this-in-production'

# Charger les variables d'environnement
load_dotenv()
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")

# Variables globales pour le syst√®me RAG
qa_chain = None
documents = None
vectorstore = None

def initialize_rag_system():
    """Initialise le syst√®me RAG au d√©marrage de l'application"""
    global qa_chain, documents, vectorstore
    
    print("üöÄ Initialisation du syst√®me RAG...")
    
    # 1. Charger les documents
    if os.path.exists("raw_documents.pkl"):
        with open("raw_documents.pkl", "rb") as f:
            raw_documents = pickle.load(f)
        print(f"‚úÖ Documents charg√©s : {len(raw_documents)} PDFs")
    else:
        folder_path = "data/"
        raw_documents = []
        
        for filename in os.listdir(folder_path):
            if filename.lower().endswith(".pdf"):
                pdf_path = os.path.join(folder_path, filename)
                reader = PdfReader(pdf_path)
                page_texts = []
                for page in reader.pages:
                    content = (page.extract_text() or "").replace("\n", " ").strip()
                    if content:
                        page_texts.append(content)
                full_text = " ".join(page_texts)
                if full_text:
                    raw_documents.append({"text": full_text, "metadata": {"source": filename}})
        
        with open("raw_documents.pkl", "wb") as f:
            pickle.dump(raw_documents, f)
        print(f"‚úÖ {len(raw_documents)} PDFs charg√©s et sauvegard√©s")
    
    # 2. Cr√©er les chunks
    if os.path.exists("documents_chunks.pkl"):
        with open("documents_chunks.pkl", "rb") as f:
            documents = pickle.load(f)
        print(f"‚úÖ Chunks charg√©s : {len(documents)} chunks")
    else:
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=350,
            chunk_overlap=120
        )
        
        documents = []
        for item in raw_documents:
            splitted_docs = text_splitter.create_documents([item["text"]], metadatas=[item["metadata"]])
            for idx, doc in enumerate(splitted_docs):
                doc.metadata["chunk_index"] = idx
            documents.extend(splitted_docs)
        
        with open("documents_chunks.pkl", "wb") as f:
            pickle.dump(documents, f)
        print(f"‚úÖ {len(documents)} chunks cr√©√©s et sauvegard√©s")
    
    # 3. Cr√©er les embeddings et FAISS
    embedding_model = HuggingFaceEmbeddings(
        model_name="intfloat/multilingual-e5-large",
        encode_kwargs={"normalize_embeddings": True}
    )
    
    if os.path.exists("faiss_index"):
        vectorstore = FAISS.load_local("faiss_index", embedding_model, allow_dangerous_deserialization=True)
        print("‚úÖ Index FAISS charg√©")
    else:
        vectorstore = FAISS.from_documents(documents, embedding_model)
        vectorstore.save_local("faiss_index")
        print("‚úÖ Index FAISS cr√©√© et sauvegard√©")
    
    # 4. Configurer le retriever hybride
    dense_retriever = vectorstore.as_retriever(
        search_type="mmr",
        search_kwargs={"k": 3, "fetch_k": 4}
    )
    
    sparse_retriever = BM25Retriever.from_documents(documents)
    sparse_retriever.k = 8
    
    hybrid_retriever = EnsembleRetriever(
        retrievers=[dense_retriever, sparse_retriever],
        weights=[0.65, 0.35]
    )
    
    # 5. Configurer le LLM
    llm = ChatOpenAI(
        model_name="gpt-4o-mini",
        temperature=0.4,
        openai_api_key=OPENROUTER_API_KEY,
        openai_api_base="https://openrouter.ai/api/v1",
        default_headers={
            "HTTP-Referer": "https://github.com/Jadir99/SmartCourseQA",
            "X-Title": "RAG Flask App",
        }
    )
    
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=hybrid_retriever,
        return_source_documents=True,
        chain_type="stuff"
    )
    
    print("‚úÖ Syst√®me RAG initialis√© avec succ√®s!")
    return qa_chain, documents, vectorstore


@app.route('/')
def landing():
    """Landing page du projet"""
    return render_template('landing.html')


@app.route('/chatbot')
def chatbot():
    """Page du chatbot"""
    return render_template('index.html')


@app.route('/quiz')
def quiz_page():
    """Page de g√©n√©ration de quiz"""
    return render_template('quiz.html')


@app.route('/api/chat', methods=['POST'])
def chat():
    """Endpoint pour le chatbot"""
    try:
        data = request.json
        question = data.get('question', '')
        
        if not question:
            return jsonify({'error': 'Question vide'}), 400
        
        # Obtenir la r√©ponse du RAG
        result = qa_chain(question)
        
        # Formater les sources
        sources = []
        for doc in result.get("source_documents", []):
            sources.append({
                'source': doc.metadata.get('source', 'Unknown'),
                'chunk': doc.metadata.get('chunk_index', 0),
                'content': doc.page_content[:200] + "..."
            })
        
        return jsonify({
            'answer': result["result"],
            'sources': sources
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/generate-quiz', methods=['POST'])
def generate_quiz():
    """G√©n√©rer un quiz bas√© sur les cours"""
    try:
        data = request.json
        topic = data.get('topic', 'intelligence artificielle')
        num_questions = data.get('num_questions', 5)
        
        # Cr√©er le prompt pour g√©n√©rer le quiz
        quiz_prompt = f"""
G√©n√®re exactement {num_questions} questions de quiz √† choix multiples (QCM) sur le sujet: "{topic}".

INSTRUCTIONS IMPORTANTES:
- G√©n√®re EXACTEMENT {num_questions} questions compl√®tes
- Chaque question doit avoir EXACTEMENT 4 options (A, B, C, D)
- Utilise les informations des cours pour cr√©er des questions pertinentes
- Les questions doivent √™tre claires et pr√©cises

FORMAT STRICT √Ä SUIVRE POUR CHAQUE QUESTION:

Question 1: [Texte de la question ici]
A) [Premi√®re option]
B) [Deuxi√®me option]
C) [Troisi√®me option]
D) [Quatri√®me option]
R√©ponse correcte: A
Explication: [Explication de pourquoi cette r√©ponse est correcte]

---

Question 2: [Texte de la question ici]
A) [Premi√®re option]
B) [Deuxi√®me option]
C) [Troisi√®me option]
D) [Quatri√®me option]
R√©ponse correcte: B
Explication: [Explication de pourquoi cette r√©ponse est correcte]

---

Continue ainsi jusqu'√† la Question {num_questions}.
N'OUBLIE PAS le s√©parateur "---" entre chaque question.
"""
        
        result = qa_chain(quiz_prompt)
        quiz_text = result["result"]
        
        print(f"üìù Quiz g√©n√©r√© pour le sujet: {topic}")
        print(f"üìä Texte brut du quiz (premiers 500 caract√®res):\n{quiz_text[:500]}...")
        
        # Parser le quiz
        questions = parse_quiz(quiz_text, num_questions)
        
        print(f"‚úÖ {len(questions)} questions pars√©es avec succ√®s")
        
        # Sauvegarder le quiz dans la session
        session['current_quiz'] = questions
        session['quiz_topic'] = topic
        
        return jsonify({
            'questions': questions,
            'topic': topic,
            'count': len(questions)
        })
    
    except Exception as e:
        print(f"‚ùå Erreur lors de la g√©n√©ration du quiz: {str(e)}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/evaluate-quiz', methods=['POST'])
def evaluate_quiz():
    """√âvaluer les r√©ponses de l'utilisateur"""
    try:
        data = request.json
        user_answers = data.get('answers', {})  # {question_index: answer}
        
        # R√©cup√©rer le quiz de la session
        quiz = session.get('current_quiz', [])
        
        if not quiz:
            return jsonify({'error': 'Aucun quiz actif'}), 400
        
        # Calculer le score
        results = []
        correct_count = 0
        
        for i, question in enumerate(quiz):
            user_answer = user_answers.get(str(i))
            correct_answer = question.get('correct_answer')
            is_correct = user_answer == correct_answer
            
            if is_correct:
                correct_count += 1
            
            results.append({
                'question_index': i,
                'question': question.get('question'),
                'user_answer': user_answer,
                'correct_answer': correct_answer,
                'is_correct': is_correct,
                'explanation': question.get('explanation')
            })
        
        score = (correct_count / len(quiz)) * 100 if quiz else 0
        
        return jsonify({
            'score': score,
            'correct_count': correct_count,
            'total_questions': len(quiz),
            'results': results
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


def parse_quiz(quiz_text, expected_questions):
    """Parse le texte du quiz g√©n√©r√© en structure JSON"""
    questions = []
    
    print(f"\nüîç D√©but du parsing du quiz...")
    print(f"üìÑ Texte complet du quiz:\n{quiz_text}\n")
    
    # Diviser par les s√©parateurs ---
    sections = quiz_text.split('---')
    print(f"üìã Nombre de sections trouv√©es: {len(sections)}")
    
    for idx, section in enumerate(sections):
        if not section.strip():
            continue
        
        print(f"\nüìå Traitement de la section {idx + 1}:")
        print(section[:200])
        
        lines = [line.strip() for line in section.strip().split('\n') if line.strip()]
        
        question_data = {
            'question': '',
            'options': {},
            'correct_answer': '',
            'explanation': ''
        }
        
        current_question_found = False
        
        for line in lines:
            # Question (plusieurs formats possibles)
            if any(line.lower().startswith(prefix) for prefix in ['question', 'q.']):
                # Extraire le texte apr√®s "Question X:" ou "Q.X:"
                if ':' in line:
                    question_data['question'] = line.split(':', 1)[1].strip()
                else:
                    question_data['question'] = line
                current_question_found = True
                print(f"  ‚úì Question trouv√©e: {question_data['question'][:50]}...")
            
            # Si pas de pr√©fixe "Question" mais c'est la premi√®re ligne et pas d'option
            elif not current_question_found and not line.startswith(('A)', 'B)', 'C)', 'D)', 'R√©ponse', 'Explication')):
                question_data['question'] = line
                current_question_found = True
                print(f"  ‚úì Question trouv√©e (sans pr√©fixe): {question_data['question'][:50]}...")
            
            # Options A, B, C, D
            elif any(line.startswith(prefix) for prefix in ['A)', 'B)', 'C)', 'D)']):
                option_letter = line[0]
                option_text = line[2:].strip()
                question_data['options'][option_letter] = option_text
                print(f"  ‚úì Option {option_letter} trouv√©e")
            
            # R√©ponse correcte
            elif any(keyword in line.lower() for keyword in ['r√©ponse correcte', 'correct answer', 'r√©ponse:', 'answer:']):
                # Extraire la lettre de la r√©ponse
                parts = line.split(':')
                if len(parts) > 1:
                    answer = parts[1].strip().upper()
                    # Extraire juste la lettre (A, B, C, ou D)
                    for char in answer:
                        if char in ['A', 'B', 'C', 'D']:
                            question_data['correct_answer'] = char
                            print(f"  ‚úì R√©ponse correcte: {char}")
                            break
            
            # Explication
            elif any(keyword in line.lower() for keyword in ['explication', 'explanation']):
                if ':' in line:
                    question_data['explanation'] = line.split(':', 1)[1].strip()
                else:
                    question_data['explanation'] = line
                print(f"  ‚úì Explication trouv√©e")
        
        # Validation: ajouter seulement si la question est compl√®te
        if (question_data['question'] and 
            len(question_data['options']) == 4 and 
            question_data['correct_answer'] in ['A', 'B', 'C', 'D']):
            questions.append(question_data)
            print(f"  ‚úÖ Question {len(questions)} ajout√©e avec succ√®s")
        else:
            print(f"  ‚ùå Question incompl√®te ignor√©e:")
            print(f"     - Question: {'‚úì' if question_data['question'] else '‚úó'}")
            print(f"     - Options: {len(question_data['options'])}/4")
            print(f"     - R√©ponse correcte: {'‚úì' if question_data['correct_answer'] else '‚úó'}")
    
    print(f"\nüìä R√©sultat final: {len(questions)}/{expected_questions} questions pars√©es")
    
    # Si pas assez de questions, afficher un avertissement
    if len(questions) < expected_questions:
        print(f"‚ö†Ô∏è ATTENTION: Seulement {len(questions)} questions valides sur {expected_questions} attendues!")
        print(f"üí° Le LLM n'a peut-√™tre pas g√©n√©r√© toutes les questions au bon format.")
    
    return questions


if __name__ == '__main__':
    # Initialiser le syst√®me RAG au d√©marrage
    initialize_rag_system()
    
    # Lancer l'application Flask
    print("\nüåê Application Flask d√©marr√©e sur http://localhost:5000")
    app.run(debug=True, host='0.0.0.0', port=5000)
