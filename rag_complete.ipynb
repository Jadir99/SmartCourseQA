{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a41fa0ef",
   "metadata": {},
   "source": [
    "## Installation des d√©pendances\n",
    "\n",
    "Ex√©cutez cette cellule en premier pour installer tous les packages n√©cessaires. Cette op√©ration peut prendre quelques minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37472d37",
   "metadata": {},
   "source": [
    "# Projet RAG - Syst√®me de Recherche et G√©n√©ration Augment√©e\n",
    "\n",
    "Ce notebook impl√©mente un syst√®me RAG (Retrieval-Augmented Generation) pour r√©pondre √† des questions bas√©es sur des documents PDF de cours d'intelligence artificielle. Le syst√®me utilise des embeddings multilingues, un retriever hybride et un mod√®le de langage pour g√©n√©rer des r√©ponses pr√©cises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca45317",
   "metadata": {},
   "source": [
    "## √âtape 1 : Imports et configuration\n",
    "\n",
    "Dans cette √©tape, nous importons les biblioth√®ques n√©cessaires et configurons l'environnement. Nous chargeons √©galement la cl√© API OpenRouter depuis un fichier .env pour √©viter de l'exposer dans le code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1e9fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# ‚úÖ Imports corrig√©s pour LangChain >= 1.0.0\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_classic.chains import RetrievalQA  # ‚úÖ for v1.0.3\n",
    "from langchain_classic.retrievers import EnsembleRetriever  # ‚úÖ changed import\n",
    "from langchain_community.retrievers import BM25Retriever  # ‚úÖ still valid\n",
    "load_dotenv()\n",
    "\n",
    "# üîë Cl√© OpenRouter\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "if not OPENROUTER_API_KEY:\n",
    "    raise ValueError(\"Merci de mettre ta cl√© OPENROUTER_API_KEY dans le fichier .env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2105134",
   "metadata": {},
   "source": [
    "## √âtape 2 : Chargement et extraction des textes des PDF\n",
    "\n",
    "Ici, nous parcourons le dossier 'data/' pour lire tous les fichiers PDF. Pour chaque PDF, nous extrayons le texte de toutes les pages, en nettoyant les espaces et les sauts de ligne. Les textes sont stock√©s dans une liste avec des m√©tadonn√©es sur la source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6750198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de cours PDF exploitables : 4 (sauvegard√© dans raw_documents.pkl)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# Charger les documents depuis le cache si disponible\n",
    "\n",
    "if os.path.exists(\"raw_documents.pkl\"):\n",
    "\n",
    "    with open(\"raw_documents.pkl\", \"rb\") as f:\n",
    "\n",
    "        raw_documents = pickle.load(f)\n",
    "\n",
    "    print(f\"Documents charg√©s depuis le cache : {len(raw_documents)} cours PDF.\")\n",
    "\n",
    "else:\n",
    "\n",
    "    folder_path = \"data/\"  # dossier contenant tous les PDFs\n",
    "\n",
    "    raw_documents = []\n",
    "\n",
    "    \n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            reader = PdfReader(pdf_path)\n",
    "\n",
    "            page_texts = []\n",
    "\n",
    "            for page in reader.pages:\n",
    "\n",
    "                content = (page.extract_text() or \"\").replace(\"\\n\", \" \").strip()\n",
    "\n",
    "                if content:\n",
    "\n",
    "                    page_texts.append(content)\n",
    "\n",
    "            full_text = \" \".join(page_texts)\n",
    "\n",
    "            if full_text:\n",
    "\n",
    "                raw_documents.append({\"text\": full_text, \"metadata\": {\"source\": filename}})\n",
    "\n",
    "    \n",
    "\n",
    "    if not raw_documents:\n",
    "\n",
    "        raise ValueError(\"Aucun texte extrait des PDFs. V√©rifie que le dossier data/ contient des fichiers PDF lisibles.\")\n",
    "\n",
    "    \n",
    "\n",
    "    # Sauvegarder les documents extraits\n",
    "\n",
    "    with open(\"raw_documents.pkl\", \"wb\") as f:\n",
    "\n",
    "        pickle.dump(raw_documents, f)\n",
    "\n",
    "    print(f\"Nombre de cours PDF exploitables : {len(raw_documents)} (sauvegard√© dans raw_documents.pkl)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab856304",
   "metadata": {},
   "source": [
    "## √âtape 3 : D√©coupage des textes en chunks\n",
    "\n",
    "Les textes longs sont divis√©s en morceaux plus petits (chunks) pour faciliter la recherche. Nous utilisons un splitter r√©cursif avec une taille de chunk de 350 caract√®res et un chevauchement de 120 caract√®res pour conserver le contexte entre les chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f863124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de chunks index√©s : 275 (sauvegard√© dans documents_chunks.pkl)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# Charger les chunks depuis le cache si disponible\n",
    "\n",
    "if os.path.exists(\"documents_chunks.pkl\"):\n",
    "\n",
    "    with open(\"documents_chunks.pkl\", \"rb\") as f:\n",
    "\n",
    "        documents = pickle.load(f)\n",
    "\n",
    "    print(f\"Chunks charg√©s depuis le cache : {len(documents)} chunks.\")\n",
    "\n",
    "else:\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "\n",
    "        chunk_size=350,\n",
    "\n",
    "        chunk_overlap=120\n",
    "\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    documents = []\n",
    "\n",
    "    for item in raw_documents:\n",
    "\n",
    "        splitted_docs = text_splitter.create_documents([item[\"text\"]], metadatas=[item[\"metadata\"]])\n",
    "\n",
    "        for idx, doc in enumerate(splitted_docs):\n",
    "\n",
    "            doc.metadata[\"chunk_index\"] = idx\n",
    "\n",
    "        documents.extend(splitted_docs)\n",
    "\n",
    "    \n",
    "\n",
    "    if not documents:\n",
    "\n",
    "        raise ValueError(\"Aucun chunk g√©n√©r√©. V√©rifie les textes extraits.\")\n",
    "\n",
    "    \n",
    "\n",
    "    # Sauvegarder les chunks\n",
    "\n",
    "    with open(\"documents_chunks.pkl\", \"wb\") as f:\n",
    "\n",
    "        pickle.dump(documents, f)\n",
    "\n",
    "    print(f\"Total de chunks index√©s : {len(documents)} (sauvegard√© dans documents_chunks.pkl)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141153cc",
   "metadata": {},
   "source": [
    "## √âtape 4 : Cr√©ation des embeddings\n",
    "\n",
    "Nous cr√©ons des repr√©sentations vectorielles (embeddings) des chunks de texte en utilisant un mod√®le multilingue. Ces embeddings sont normalis√©s pour am√©liorer la similarit√© cosinus. Nous stockons ensuite ces vecteurs dans une base de donn√©es FAISS pour une recherche rapide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4706ef3",
   "metadata": {},
   "source": [
    "## Note importante sur la sauvegarde\n",
    "\n",
    "Les √©tapes pr√©c√©dentes sauvegardent automatiquement les r√©sultats interm√©diaires :\n",
    "- **raw_documents.pkl** : Documents extraits des PDF\n",
    "- **documents_chunks.pkl** : Chunks de texte d√©coup√©s\n",
    "- **faiss_index/** : Index FAISS avec les embeddings\n",
    "\n",
    "Si vous r√©ex√©cutez le notebook, ces fichiers seront charg√©s directement depuis le disque au lieu d'√™tre recalcul√©s, ce qui acc√©l√®re consid√©rablement le temps d'ex√©cution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3fca59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index FAISS construit avec embeddings e5.\n",
      "Index FAISS sauvegard√© dans le dossier 'faiss_index'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "\n",
    "    model_name=\"intfloat/multilingual-e5-large\",\n",
    "\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Charger l'index FAISS depuis le disque si disponible\n",
    "\n",
    "if os.path.exists(\"faiss_index\"):\n",
    "\n",
    "    vectorstore = FAISS.load_local(\"faiss_index\", embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "    print(\"Index FAISS charg√© depuis le disque.\")\n",
    "\n",
    "else:\n",
    "\n",
    "    vectorstore = FAISS.from_documents(documents, embedding_model)\n",
    "\n",
    "    print(\"Index FAISS construit avec embeddings e5.\")\n",
    "\n",
    "    # Sauvegarder l'index FAISS sur le disque pour √©viter de le recalculer\n",
    "\n",
    "    vectorstore.save_local(\"faiss_index\")\n",
    "\n",
    "    print(\"Index FAISS sauvegard√© dans le dossier 'faiss_index'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408d3b22",
   "metadata": {},
   "source": [
    "## √âtape 5 : Configuration du retriever hybride\n",
    "\n",
    "Pour am√©liorer la pr√©cision de la recherche, nous utilisons un retriever hybride qui combine la recherche dense (bas√©e sur les embeddings) et la recherche sparse (BM25, bas√©e sur les mots-cl√©s). Le retriever dense utilise MMR pour la diversit√©, et nous pond√©rons les r√©sultats avec 65% pour dense et 35% pour sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f74d54bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",  # Maximum Marginal Relevance pour diversit√©\n",
    "    search_kwargs={\"k\": 3, \"fetch_k\": 4}\n",
    ")\n",
    "\n",
    "sparse_retriever = BM25Retriever.from_documents(documents)\n",
    "sparse_retriever.k = 8\n",
    "\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[dense_retriever, sparse_retriever],\n",
    "    weights=[0.65, 0.35]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a3365a",
   "metadata": {},
   "source": [
    "## √âtape 6 : Configuration du mod√®le de langage\n",
    "\n",
    "Nous configurons le mod√®le GPT-4o-mini via OpenRouter. La temp√©rature est r√©gl√©e √† 0.4 pour des r√©ponses plus factuelles. Nous utilisons des en-t√™tes personnalis√©s pour respecter les exigences d'OpenRouter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1b61e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0.4,  # temp√©rature plus basse pour des r√©ponses plus factuelles\n",
    "    openai_api_key=OPENROUTER_API_KEY,\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "    default_headers={\n",
    "        \"HTTP-Referer\": \"https://github.com/your-user/your-repo\",\n",
    "        \"X-Title\": \"RAG Notebook\",\n",
    "    }\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=hybrid_retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type=\"stuff\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbace3ae",
   "metadata": {},
   "source": [
    "## √âtape 7 : Exemple de recherche et g√©n√©ration de r√©ponse\n",
    "\n",
    "Nous testons le syst√®me avec une question sur les d√©fis de l'intelligence artificielle. Le retriever r√©cup√®re les chunks pertinents, puis le mod√®le g√©n√®re une r√©ponse bas√©e sur ces informations. Les sources utilis√©es sont affich√©es pour la transparence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17c361ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√©ponse du mod√®le :\n",
      "Les principaux d√©fis de l'intelligence artificielle (IA) incluent :\n",
      "\n",
      "1. **Difficult√©s li√©es aux donn√©es ou √† l‚Äôenvironnement** : Les biais humains pr√©sents dans les donn√©es peuvent entra√Æner des discriminations dans des domaines tels que le recrutement, le cr√©dit, la justice ou la sant√©. Par exemple, la reconnaissance faciale peut √™tre moins pr√©cise pour certaines ethnies si les donn√©es utilis√©es pour l'entra√Ænement sont d√©s√©quilibr√©es.\n",
      "\n",
      "2. **Limites de l‚ÄôIA pour r√©soudre le probl√®me** : L'IA peut √™tre limit√©e dans sa capacit√© √† traiter des situations complexes ou impr√©vues, ce qui peut affecter son efficacit√©.\n",
      "\n",
      "3. **Co√ªts computationnels et √©nerg√©tiques** : Certains mod√®les d'IA, comme les grands mod√®les de langage, n√©cessitent d'importantes ressources mat√©rielles et √©nerg√©tiques pour leur entra√Ænement, ce qui peut √™tre tr√®s co√ªteux.\n",
      "\n",
      "4. **Limites √©thiques et l√©gales** : L'IA soul√®ve des questions de responsabilit√© et de r√©glementation. Par exemple, il peut √™tre difficile de d√©terminer qui est responsable si l'IA prend une d√©cision erron√©e.\n",
      "\n",
      "5. **Explicabilit√© et interpr√©tabilit√©** : Les mod√®les complexes, tels que les r√©seaux de neurones profonds, peuvent √™tre difficiles √† expliquer et √† interpr√©ter, ce qui pose des d√©fis pour leur adoption dans des contextes o√π la transparence est essentielle.\n",
      "\n",
      "6. **Perte de comp√©tences et de productivit√©** : L'impl√©mentation de solutions d'IA peut entra√Æner une d√©pendance excessive aux technologies, ce qui peut provoquer une perte de comp√©tences au sein des √©quipes et une baisse de productivit√©.\n",
      "\n",
      "Ces d√©fis doivent √™tre pris en compte lors du d√©veloppement et de l'impl√©mentation de syst√®mes d'intelligence artificielle.\n",
      "\n",
      "Sources utilis√©es :\n",
      "Source 0 (Cours_IA_et_Applications_S1.pdf, chunk 60)\n",
      "6.Identifier les d√©fis et limites possibles 1.Difficult√©s li√©es aux donn√©es ou √† l‚Äôenvironnement. 2.Limites de l‚ÄôIA pour r√©soudre le probl√®me. ...\n",
      "\n",
      "Source 1 (Cours_IA_et_Applications_S1.pdf, chunk 48)\n",
      "biais humains pr√©sents dans les donn√©es. ‚Ä¢Cons√©quences : discrimination dans le recrutement, cr√©dit, justice ou sant√©. ‚Ä¢Exemple : reconnaissance faciale moins pr√©cise pour certaines ethnies si donn√©es  d√©s√©quilibr√©es . Les D√©fis de l‚ÄôIA 21/09/2025 IA et Applications 263-Explicabilit√© et interpr√©tabi ...\n",
      "\n",
      "Source 2 (Cours_IA_et_Applications_S2.pdf, chunk 56)\n",
      "perte de comp√©tences, une baisse de productivit√© et des co√ªts  suppl√©mentaires li√©s au recrutement et √† la formation de nouveaux employ√©s. Elle  souhaite mettre en place une solution efficace pour comprendre les causes de ces  d√©parts, anticiper les risques de turnover et am√©liorer la fid√©lisation d ...\n",
      "\n",
      "Source 3 (Cours_IA_et_Applications_S1.pdf, chunk 52)\n",
      "computationnel et √©nerg√©tique ‚Ä¢Certains mod√®les n√©cessitent des ressources mat√©rielles et √©nerg√©tiques  importantes . ‚Ä¢Exemple : entra√Ænement de grands mod√®les de langage (LLM) ‚Üí Tr√®s couteux. 6-Limites √©thiques et l√©gales ‚Ä¢L‚ÄôIA soul√®ve des questions de responsabilit√© et de r√©glementation : ‚Ä¢Qui est ...\n",
      "\n",
      "Source 4 (Cours_IA_et_Applications_S1.pdf, chunk 59)\n",
      "ou de nettoyage. 21/09/2025 IA et Applications 30Eg. T√¢ches √† r√©aliser -Suite 5. √âtablir les contraintes et besoins techniques 1.Temps, budget, confidentialit√©, pr√©cision attendue. 2.Ressources mat√©rielles ou logicielles n√©cessaires. 6.Identifier les d√©fis et limites possibles 1.Difficult√©s li√©es au ...\n",
      "\n",
      "Source 5 (Cours_IA_et_Applications_S1.pdf, chunk 8)\n",
      "Artificielle est une discipline qui vise √† concevoir des syst√®mes capables d‚Äôaccomplir  des t√¢ches n√©cessitant normalement l‚Äôintelligence humaine .Def. ‚Ä¢Angle scientifique : L‚ÄôIA est une discipline scientifique et technologique de l‚Äôinformatique,  au croisement des math√©matiques, de la logique, des  ...\n",
      "\n",
      "Source 6 (Cours_IA_et_Applications_S2.pdf, chunk 60)\n",
      "taux √©lev√© de turnover au sein de ses √©quipes, ce qui  entra√Æne une perte de comp√©tences, une baisse de productivit√© et des co√ªts  suppl√©mentaires li√©s au recrutement et √† la formation de nouveaux employ√©s. Elle  souhaite mettre en place une solution efficace pour comprendre les causes de ces  d√©par ...\n",
      "\n",
      "Source 7 (Cours_IA_et_Applications_S2.pdf, chunk 78)\n",
      "de turnover au sein de ses √©quipes, ce qui  entra√Æne une perte de comp√©tences, une baisse de productivit√© et des co√ªts  suppl√©mentaires li√©s au recrutement et √† la formation de nouveaux employ√©s. Elle  souhaite mettre en place une solution efficace pour comprendre les causes de ces  d√©parts, anticip ...\n",
      "\n",
      "Source 8 (Cours_IA_et_Applications_S2.pdf, chunk 6)\n",
      "de d√©veloppement de projets d'IA En Data -Driven les d√©cisions sont prises uniquement sur la base de l‚Äôanalyse de donn√©es. ‚Ä¢Objectif et bas√© sur des faits mesurables. ‚Ä¢Utilise des techniques d‚Äôanalytique, de statistique et de machine learning . ‚Ä¢d√©pendance excessive aux donn√©es disponibles (si les d ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Expliquer les principaux d√©fis de l‚Äôintelligence artificielle\"\n",
    "\n",
    "result = qa_chain(query)\n",
    "\n",
    "print(\"R√©ponse du mod√®le :\")\n",
    "print(result[\"result\"])\n",
    "\n",
    "print(\"\\nSources utilis√©es :\")\n",
    "for i, doc in enumerate(result[\"source_documents\"]):\n",
    "    print(f\"Source {i} ({doc.metadata.get('source')}, chunk {doc.metadata.get('chunk_index')})\")\n",
    "    print(doc.page_content[:300], \"...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f737bb",
   "metadata": {},
   "source": [
    "## √âtape 8 : G√©n√©ration d'un quiz\n",
    "\n",
    "Enfin, nous demandons au syst√®me de g√©n√©rer un quiz bas√© sur les documents. Cela d√©montre la capacit√© du RAG √† cr√©er du contenu nouveau et pertinent √† partir des informations r√©cup√©r√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5a2d849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quiz g√©n√©r√© :\n",
      "1. Quelle est l'une des principales pr√©occupations √©thiques li√©es √† l'intelligence artificielle ?\n",
      "   a) La rapidit√© des calculs  \n",
      "   b) Le co√ªt computationnel  \n",
      "   c) La responsabilit√© en cas d'erreur de l'IA  \n",
      "   d) La taille des mod√®les  \n",
      "   **R√©ponse : c) La responsabilit√© en cas d'erreur de l'IA**\n",
      "\n",
      "2. Quel est un exemple de d√©fi que l'IA doit surmonter lors de l'apprentissage √† partir de donn√©es ?\n",
      "   a) L'augmentation des ressources humaines  \n",
      "   b) La g√©n√©ralisation et le transfert de mod√®les  \n",
      "   c) La cr√©ation de nouveaux algorithmes  \n",
      "   d) L'optimisation des co√ªts  \n",
      "   **R√©ponse : b) La g√©n√©ralisation et le transfert de mod√®les**\n",
      "\n",
      "3. Dans quel domaine l'IA peut-elle √™tre utilis√©e pour analyser des tendances, comme le chiffre d'affaires mensuel ?\n",
      "   a) En √©ducation  \n",
      "   b) En sant√©  \n",
      "   c) En entreprise  \n",
      "   d) Dans le divertissement  \n",
      "   **R√©ponse : c) En entreprise**\n",
      "\n",
      "4. Quel type d'IA apprend en interagissant avec un environnement et en recevant des r√©compenses ou des p√©nalit√©s ?\n",
      "   a) IA par apprentissage supervis√©  \n",
      "   b) IA par apprentissage non supervis√©  \n",
      "   c) IA par renforcement  \n",
      "   d) IA par apprentissage par transfert  \n",
      "   **R√©ponse : c) IA par renforcement**\n",
      "\n",
      "5. Quelle m√©thode de prise de d√©cision repose principalement sur l'exp√©rience et l'intuition des d√©cideurs ?\n",
      "   a) D√©cision bas√©e sur les donn√©es  \n",
      "   b) D√©cision par intuition  \n",
      "   c) D√©cision algorithmique  \n",
      "   d) D√©cision par consensus  \n",
      "   **R√©ponse : b) D√©cision par intuition**\n"
     ]
    }
   ],
   "source": [
    "query_quiz = \"\"\"\n",
    "G√©n√®re 5 questions de quiz avec 4 choix avec r√©ponses √† partir des passages pertinents\n",
    "des cours sur l‚Äôintelligence artificielle.\n",
    "\"\"\"\n",
    "\n",
    "result_quiz = qa_chain(query_quiz)\n",
    "\n",
    "print(\"Quiz g√©n√©r√© :\")\n",
    "print(result_quiz[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
